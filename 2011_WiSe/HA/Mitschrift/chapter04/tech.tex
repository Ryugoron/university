\chapter{Grundlegende Techniken}

\section{Lösen von Rekursionsgleichungen}

\subsection{Raten und Induktion}

Diesen Ansatz ist immer dann zu wählen, wenn einem die Laufzeit des Algorithmus sofort klar ist.\\

Das ganze führt natürlich nur zum Ziel, wenn die Induktion aufgeht. Man kann also prinzipiell ziemlich lange raten, bis man auf ein vernünftiges Ergebnis kommt.

\subsection{Auflösen und Muster erkennen}

Beim Auflösen, führen wir die Rekursion Schritt für Schritt aus. Sobald wir ein Muster beim Auflösen erkennen, können wir es bis auf Ebene $k$ hinschreiben und dann analysieren, für welches $k$ der Anker erreicht wird. Diesen kann man dann in die Gleichung einsetzen und wird dadurch die endgülitge Laufzeit erhalten.

\textbf{Beispiel:} Mergesort\\
Annahme: $n = 2^k$.
$$
T(n) = \left\{
\begin{array}{lr}
0 & , n = 1\\
2 T\left( \frac{n}{2} \right) + n - 1, \text{sonst}
\end{array}
\right.
$$

$$
\begin{array}{rcl}
T(n) &=& 2 T\left( \frac{n}{2} \right) + n - 1\\
&=& 2 \cdot \left( 2 T\left( \frac{n}{2^2} \right) + \frac{n}{2} - 1\right) + n - 1\\
&=& 2^2 T\left( \frac{n}{2^2} \right) 2n -2^1 - 2^0\\
&=& 2^3 T \left( \frac{n}{2^3} \right) 3n - 2^2 - 2^ 1 - 2^0\\
&& \text{Nach k Schritten}\\
&=& 2^k T \left( \frac{n}{2^k} \right) +  kn - \overset{k-1}{\underset{i=0}{\sum}} 2^i\\
&& k = \log n \text{ (Beim Anker)}\\
&=& 2^{\log n} \cdot T(1) + n \cdot \log n - \frac{2^{\log n} - 1}{2 - 1}\\
&=& n \log n - n + 1
\end{array}
$$

\subsection{Rekursionbaum analysieren}

Die Rekursionsbaummethode läuft ähnlich zur Einsetzmethode. Hier werden die einzelnen Schritte der Rekursion aber als Baum dargestellt und danach ausgewertet.\\
Beispiel:\\
$$
T(n) \leq \left\{ 
\begin{array}{lr}
0 &, n = 1\\
3 \cdot T (\frac{n}{2} ) + cn & \text{, sonst}
\end{array}
\right.
$$

%%\begin{tikzpicture}[level/.style={sibling distance=60mm/#1}]
%%\node[circle,draw](11){$T(n)$};
%%\node[circle,draw](21) [below, left of =11] {$T(\frac{n}{2}$};
%%\node[circle,draw](31) [below, left of=21] {$T(\frac{n}{4}$};
%%\node[circle,draw](32) [right of = 31] {$T(\frac{n}{4}$};
%%\node[circle,draw](33) [right of =32] {$T(\frac{n}{4}$};
%%\node[circle,draw](22) [right of = 21] {$T(\frac{n}{2}$};
%%\node[circle,draw](34) [right of = 33] {$T(\frac{n}{4}$};
%%\node[cricle,draw](35) [right of = 34] {$T(\frac{n}{4}$};
%%\node[cricle,draw](36) [right of = 35] {$T(\frac{n}{4}$};
%%\node[circle,draw](23) [right of = 22] {$T(\frac{n}{2}$};
%%\node[circle,draw](37) [right of = 36] {$T(\frac{n}{4}$};
%%\node[cricle,draw](38) [right of = 37] {$T(\frac{n}{4}$};
%%\node[cricle,draw](39) [right of = 38] {$T(\frac{n}{4}$};
%%\end{tikzpicture}

Graph is tbd

\subsection{Master Theorem}

\begin{description}

\item{\bfseries Satz:} Sei $a \geq 1 \; , \; n > 1 \; , \; c>0$\\
$$
f \; : \; \N \rightarrow \R^+ \quad , \quad t \; : \; \N \rightarrow \R^+
$$
Sei
$$
T(n) = \left\{
\begin{array}{lr}
t(n) & , n < c\\
a \cdot T(\frac{n}{b}) + f(n) & \text{, sonst}
\end{array}
\right.
$$
eine Rekursion.\\
Dann gilt

\begin{enumerate}[\bfseries (i)]

\item Wenn
$$
\exists \varepsilon > 0 \; : \; f(n) = O\left( n^{\log_b a \; - \varepsilon} \right),
$$
dann ist
$$
T(n) = \Theta \left( n^{\log_b a} \right)
$$

\item Wenn
$$
f(n) = \Theta \left( n^{\log_b a} \right),
$$
dann ist
$$
T(n) = \Theta \left( n^{\log_b a} \cdot \log n \right)
$$

\item Wenn
$$
\exists \varepsilon > 0 \; : \; f(n) = \Omega \left( n^{\log_b a \; + \varepsilon} \right) \land \exists d < 1 \; : \; a\cdot f\left( \frac{n}{b} \right) \leq c \cdot f(n),
$$
dann ist
$$
T(n) = \Theta \left( f(n) \right)
$$

\end{enumerate}

\item{\bfseries Beispiele:}

\begin{enumerate}[\bfseries (1)]

\item Karatsuba (mit Optimierung)\\
$T(n) \leq 3 \cdot T( \frac{n}{2} ) + O(n)$\\
Das Mastertheorem geht mit $a = 3, \; b=2,\; f(n) = cn,\; \varepsilon  = 0.25$\\
$cn \leq n^{1.5 - \varepsilon} = n^{1.25} = O(n^{\log_2 3 \; - \varepsilon}$
$$
\Rightarrow T(n) = \Theta \left( n^{\log_2 3} \right)
$$

\item Karatsuba (ohne Optimierung)\\
$T(n) = 4 \cdot T(\frac{n}{2} ) + O(n)$\\
Mastertheorem geht mit $a=4, \; b=2, \; f(n) = cn, \; 0 < \varepsilon \leq 1$\\
$f(n) = O(n^{2 - \varepsilon})$
$$
\Rightarrow T(n) = \Theta (n^2)
$$

\item Mergesort\\
$T(n) = 2 \cdot T( \frac{n}{2} ) + n - 1$\\
Das Mastertheorem geht, mit $a = 2, b=2, f(n) = n - 1$\\
$f(n) = n - 1 = \Theta ( n^{\log_2 2}) = \Theta (n)$
$$
\Rightarrow \Theta (n \cdot \log n)
$$

\item Binäre Suche\\
$T(n) = T(\frac{n}{2}) + c$\\
Mastertheorem geht, mit $a = 1, b = 2, f(n) = c$\\
Das Mastertheorem geht, mit $a = 1, b=2, f(n) = c$\\
$c = \Theta ( n^{\log_2 1} ) = \Theta (n^0) = \Theta (1)$
$$
\Rightarrow T(n) = \Theta (\log n)
$$

\end{enumerate}

\item{\bfseries Beweisidee:} Lösen wir den Rekursionsbaum der allgemeinen Gleichung auf, so erhalten wir die folgende Form:\\
Wir in der nächsten Ebene pro Knoten $a$ neue Knoten und teilen unser $n$ durch $b$. Die Höhe des Baumes ist damit $\log_b n$.
$$
\Rightarrow T(n) = \sum_{i = 0}^{\log_b n} a^i f\left( \frac{n}{b^i} \right)
$$
Nun können wir daraus mehrere Fälle gewinnen:\\
Falls auf jeder Ebene die selbe Zahl steht, gewinnen Fall 2 aus dem Satz.\\
Falls die Kosten pro Ebene immer kleiner werden, erhalten wir Fall 3.\\
Und falls die Kosten immer mehr werden, erhalten wir den ersten Fall1.\\

\item{\bfseries Grenzfälle:} Wo geht das Mastertheorem nicht?\\
Bei mehr als einem verscheidenen Rekurisonsaufruf, z.B. $T(n) = 2 \cdot T(\frac{n}{2}) + T(\frac{n}{3}) + O(n)$\\

Wenn keiner der Fälle greift, z.B. $T(n) = 2 \cdot T(\frac{n}{2}) + \Theta ( n \cdot \log n)$

\end{description}

\section{Divide \& Conquer}

\textbf{Def.:} Unterteile ein großes Problem in kleinere Probleme. Löse diese einzeln und setzte die Teilergebnisse zusammen.\\

\textbf{Bsp.:} Mergesort, Quicksort\\

Um Divide\&Conquer Algorithmen zu Analysieren muss man häufig Rekursionsgleichungen analysieren.

\subsection{Beispiel: Multiplizieren von Zahlen}

Gegeben sind zwei Zahlen $a,b \in \N$\\
Gescuht ist $ a \cdot b$

\subsubsection{Schulmethode}

\textbf{Beispiel:} Sei $a=1234$ und $b = 512$

$$
\begin{array}{cccccccc}
1 & 2 & 3 & 4 & \cdot & 5 & 1 & 2\\
\hline
&&&&2&4&6&8\\
&&&1&2&3&4&\\
&&6&1&7&0&&\\
\hline
&&6&3&1&8&0&8
\end{array}
$$

Sei $n := $ Anzahl der Ziffern (ist eine Zahl kürzer als die andere, füllen wir sie am Anfang mit 0en auf).\\
$\Rightarrow n^2$ Multiplikationen und $n^2$ Additionen $\Rightarrow \Theta (n^2)$\\

Dies gilt für jedes Zahlensystem, da sich die Anzahl der Ziffern mit den Systemen immer weiter verändern.\\

\subsubsection{Divide\&Conquer beim Multiplizieren}

Wir teilen $a,b$ in 2 kleinere Zahlen (weniger Ziffern) und lösen das ganze rekursiv. Wir nehmen jetzt einmal an, dass wir uns im Binärsystem bewegen.

$$
a = a_h \cdot 2^{\left\lceil \frac{n}{2} \right\rceil} + a_l
$$
$$
b = b_h \cdot 2^{\left\lceil \frac{n}{2} \right\rceil} + b_l
$$

$$
\Rightarrow \begin{array}{rcl}
a \cdot b &=& \left( a_h \cdot 2^{\left\lceil \frac{n}{2} \right\rceil} + a_l \right) \left( b_h \cdot 2^{\left\lceil \frac{n}{2} \right\rceil} + b_l \right)\\
&=& a_hb_h \cdot 2^{2 \left\lceil \frac{n}{2} \right\rceil} + a_hb_l \cdot 2^{\left\lceil \frac{n}{2} \right\rceil}+ a_lb_h \cdot 2^{\left\lceil \frac{n}{2} \right\rceil} + a_lb_l
\end{array}
$$
Das führt zu:
\begin{itemize}
\item 2 Multiplikationen mit $\frac{n}{2}$ Bits
\item 2 x Bitshifting
\item 3 Additionen
\end{itemize}
Anker bei 1,2,4 Bits (egal so lange eine Konstante gewählt wird).\\

\textbf{Laufzeit:}
$$
T(n) \leq \left\{ \begin{array}{lr}
O(1) &, n = O(1)\\
4 T(\frac{n}{2}) + O(n) &, sonst
\end{array} \right.
$$

Diese Formel wird an dieser Stelle nicht aufgelöst, da das Ergbnis mit $\Theta (n^2)$ nicht besser geworden ist.\\

\textbf{Optimierung:}\\

Unser Problem ist, das wir 4 rekursive Aufrufe haben. Doch durch einen genialen Einfall, können wir das ganze auf 3 reduzieren.\\

Betrachten wir einmal die Form von eben, aber wir streichen die Verschiebung durch $2^k$.

$$
\begin{array}{crcl}
&\left( a_h + a_l \right) \left( b_h + b_l \right) &=& a_hb_h + a_hb_l + a_lb_j + a_lb_l\\
\Leftrightarrow& a_hb_l + a_lb_j &=& \left( a_h + a_l \right) \left( b_h + b_l \right) - a_hb_h - a_lb_l
\end{array}
$$

Hier sieht man, dass wir mit 3 Gleichungen auf unsere 4 Terme kommen können. Das bedeutet für unsere Rekursion:

$$
T(n) \leq \left\{ \begin{array}{lr}
O(1) &, n \leq 3\\
4 T(\frac{n}{2}) + O(n) &, sonst
\end{array} \right.
$$

\textbf{Lösen der Rekursionsgleichung}

$$
\begin{array}{rcl}
T(n) &\leq& 3 \cdot T\left( \frac{n}{2} \right) + cn\\
&\leq& 3 \cdot \left( 3 \cdot T \left( \frac{n}{2^2} \right) + c \cdot \frac{n}{2} \right) + cn\\
&& ... \\
&\leq& 3^k \cdot T\left( \frac{n}{2^k}\right) + cn \cdot \left( \overset{\log k}{\underset{i=0}{\sum}} \frac{3^i}{2^i}\right)\\
&& \text{Nach }k=\log n\text{ Schritten haben wir den Anker erreicht}\\
&=& 3^{\log n} \cdot O(1) + cn \cdot \left( \overset{\log k}{\underset{i=0}{\sum}} \frac{3^i}{2^i}\right)\\
&=& c\cdot \frac{\left( \frac{3}{2}\right)^{\log n + 1} - 1}{\frac{3}{2} - 1}\\
&=& 2cn\cdot \frac{3}{2} \cdot \left( \frac{3}{2} \right)^{\log n}\\
&=&3cn^{\log 3}
\end{array}
$$

Die Laufzeit ist also $T(n) \in O(n^{\log 3})$, wobei $n^{\log 3} \approx n^{1.58}$ ist, was weniger ist als $n^2$.

\subsection{Beispiel: Closest Pair Problem}

Bei diesem Problem haben wir $n$ Punkte in der Ebene gegeben und wollen das Paar von Punkten finden, so dass der Abstand dieser Punkte das Minimum aller Abstände der menge ist.

\subsubsection{Naiver Ansatz}
Wir berechnen alle Abstände und nehmen davon das minimum.\\
Alle Abstände zu berechnen dauert $\left( n \choose 2 \right)$, das minimum einer Menge kann man in $n-1$ herraus finden.
$\Rightarrow \Theta (n^2)$

\subsubsection{Closest-Pair mit Divide \& Conquer}
Wir teilen die Punktmenge in 2 gleichgroße Hälften indem wir nach $x$ Koordinate sortieren.
Wir nehmen $q$ als Median dieser Menge und definieren:
$$
P_L = \{ p \in P \; | \;  p_x \leq q_x \} \quad , \quad P_R = \{ p \in P \; | \; p_x > q_x\}
$$
Finde in diesen Mengen rekrusiv das engste Paar.\\
$\delta_L = CP(P_L) \; , \; \delta_R = CP(P_R)$\\
$\delta = \min \{ \delta_L \; , \; \delta_R \}$\\

Nun muss dieses $\delta$ aber nicht der kleinste Abstand sein, da das engeste Paar genau auf die beiden Teile verteilt sein könnte.

\begin{description}
\item{\bfseries Beobachtung 1:} Wen es ein engstes Paar $p,q$ mit $p\in P_L \; , \; q \in P_R$ gibt, so liegt es in einem $2 \delta$ Streifen um die Mittellinie $q_x$.
\item{\bfseries Beobachtung 2:} Wenn es ein engeres Paar gitb, so muss es zusätzlich im Rechteck $(\delta , 2\delta)$ zentriert um die Mittelachse liegen.
\item{\bfseries Beobachtung 3:} Der Abstand zwischen 2 Punkten wird üblicherweise mit $\sqrt{\|\| p,q\|\|}$ berechent. Aber auf unserer RAM können wir die Wurzel leider nicht einfach so berechnen. Aber da wir nur die Abstände vergleichen wollen, können wir auch die Quadrate der Abstände vergleichen.
\item{\bfseries Volumenbetrachtung:} Wir wollen $n$ Punkte auf eine Fläche F setzten mit $\forall p,q \; : \; d(p,q) \geq 1$.\\
Um es leichter Abzuschätzen erlauben wir $d(p,q)\geq 0.5$ können wir das ganze mit disjunkten Kreisen beschreiben. Jedem Punkt gehört von einem solchen Kreis ein Viertel.
$\Rightarrow $ Die Menge der Punkte pro Rechtekc ist beschänkt.
\end{description}

Aus diesen Betrachtungen können wir folgendes schließen:\\
Alle Punkte in $P_L$ haben Mindestabstand $\delta$.\\
Alle Punkte in $P_R$ haben Mindestabstand $\delta$.\\
Wie viele Punkte aus $P_L$ können in dem Rechteck R leigen? Das Rechteck hat die Maße $(\delta , \delta)$ und aus unserer Volumenbetrachtung folgt, dass jedem Punkt $\frac{1}{4}(\frac{\delta}{2})^2 \cdot \pi = \frac{3}{16} \delta^2$ Fläche gehört.\\
Das heißt, dass in der Fläche $R_L$ maximal $\left\lfloor \frac{16}{3}\right\rfloor = 5$.\\

Die selbe Überlegung können wir für $R_R$ anstellen.\\

$\Rightarrow$ Wir müssen pro Rechteck nur den Abstand zu 9 Nachfolgern berechnen. Dann nehmen wir immer das globale Minimum von $\delta$.\\

Die Rechtecke können wir optimal Durchmustern, indem wir die Punkte im $2 \delta$ Bereich nehmen (geht leicht, da wir eine sortierte Liste haben) und diese nun auch aufsteigend nach y - Koordinate sortieren und jeweils 10 Punkte vergleichen.

\textbf{Optimierung:} Wir müssten nur in jedem Rekursionsschritt 2 mal Sortieren. Dies ist unnötig, da wir die Liste 2 mal Vorsortieren können und dann in jedem Schritt maximal lineare Zeit benötigen um die Listen für den nächsten Schritt zu gewinnen.\\
Im Falle der x-Kooridnaten brauchen wir bloß die Listen zu splitten. Im Falle der y-Koordinaten müssen wir einen umgekehrten Mergealgorithmus anwenden (der bekannte aus Mergesort).\\

\textbf{Laufzeit:}\\
Vorverarbeitung: $O(n) \cdot \log n$\\
Im Algorithmus: $O(n) = 2 \cdot T(\frac{n}{2}) = O (n \cdot \log n)$