\documentclass[ngerman,a4paper,11pt]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{babel}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

\newtheorem{lemma}{\bfseries Theorem}

\begin{document}

\section{Randomized Rounding}

\subsection{Set Cover}

Given is $E = \{ e_1, ..., en \}$ set of elements,
$S_1,..,S_m$ with $S_i \subset E \forall 1 \leq i \leq m$ and weights
$w_j \geq 0 \forall j \in [m]$.\\
We want to find $I \subset \{ 1 ,..., m \}$ such that $\underset{j \in I}{\sum} w_j$ is
minimized subject ot $underset{j \in I}{\bigcup} S_j = E$.\\

\textbf{Integer Program}\\
$$\begin{array}{rrcl}
\min & \overset{m}{\underset{j=1}{\sum}} w_j x_j &&\\
s.t. & \underset{j:e_i\in S_j}x_j & \geq & 1 , \quad i=1,..,n\\
   & x_k \in \{0,1\}, \quad j=1,..,n
\end{array}$$

Solve the relaxation of the IP you get the optimal solution $X^*$ for
the LP. Next we want to round every component $x_j \mapsto \left\{ \begin{array}{c} 1 \\ 0\end{array}\right.$
To gain an integer solution.\\

We know from the relaxed condition, that $0 \leq x_j^* \leq 1$ so we will set
$P[S_j \text{ in the solution}] = x_j^*$.\\

Now $X_j = \left\{ \begin{array}{lr} 1&S_j\text{ in the solution}\\0&\text{otherwise}\end{array}\right.$
is the random variable that indicates, whether $S_j$ is in the solution.\\

With this we can calculate the expected cost of the integer program.\\
$$\begin{array}{rcl}
E[\overset{m}{\underset{j=1}{\sum}} w_j x_j &=& \overset{m}{\underset{j=1}{\sum}} w_j P[x_j=1]\\
&=&\overset{m}{\underset{j=1}{\sum}} w_j x_j^* \\
&=& Z_{LP}^*\leq Z_{IP}^* = OPT
\end{array}$$

This looks to good to be true and our suspissions are fullfilled, because with this simple rounding
we might not have a feasable solution.\\

We now look at the probaility with which an elemnt is not covered.\\

$$\begin{array}{rcl}
\forall e_i \; : \; P[e_i\text{ not covered}] &=& \underset{j:e_i\in S_j}{\prod} (1-x_j^*) \\
&\leq& \underset{j:e_i\in S_j}{\prod} e^{-x_j^*} \\
&=& e^{-\underset{j:e_i\in S_j0}{\sum} x_j^*} \\
&\overset{LP constraint}{\geq}& e^{-1}
\end{array}$$

With this error we will now construct an algorithm, that satisfies the following conditions
\begin{itemize}
   \item The Failiureprobability has to be less than $n^{-c}$ with $c$ constant.
   \item We will run the algorithm many times, until it is satisfied.
   \item The constant has to be great enough, that the expected times of iterations is small.
\end{itemize}

\textbf{Solution Idea}:\\
Toss a coin for $S_j \quad \forall j$ more than once.\\

To be precise, we will toss the coin $c \cdot \log \, n$ times. The probabilities will
be the same es in the first rounding.\\

Put $S_j$ in the solution if the coin comes up heads AT LEAST once\\
$P[X_j=1] = (1-x_j)^{c \cdot \ln \, n}$ so the probability, that an edge was not covered
is
$$\begin{array}{rcl}
P[e_i\text{ not covered}] &=& \underset{j:e_i\in S_j}{\prod} (1-x_j)^{c\cdot \log \, n}\\
&\leq& \underset{j:e_i \in S_j}{\prod} e^{-x_j^*(c\cdot \log \, n)}\\
&=& e^{-(c\cdot \log \, n)\sum x_j^*}\\
&\leq& \frac{1}{n^c}
\end{array}$$


Now we have to merge all the probabilites, but keep in mind, that they are not indipended
$$\begin{array}{rcl}
   P[\exists e_t\text{ not covered}] &\leq& \underset{i=1}{\overset{n}{\sum}} P[e_i \text{ not covered}]  \\
    &\leq& n\cdot \frac{1}{n^c}\\
    &\leq& \frac{1}{n^{c-1}}
\end{array}$$

\begin{lemma}\label{randround:apx}\mdseries\itshape
$\mathcal{A}$ is a (randmized) $O(\log \, n)$-approximation algorithm
and produces a set-cover with high probability.
\end{lemma}

\begin{description}
   \item{\bfseries Proof ~\ref{randround:apx}:}\\
      To proof this, we will first show a slitly stronger claim on the approximation factor:\\
      If $\mathcal{A}$ returnes a set-cover, that the approximation-factor is $O(\log \, n)$.\\

      $x_j^* \in [0,1], \; c\log \, n \geq 1$\\
      $p_j'(x_j) = (c \log \, n)(1-x_j^*)^{c\log \, n -1} \leq c \log n$\\
      $pj(0)=0 \Rightarrow p_j(x_j^*) \leq (c \log \, n)x_j^*$\\

      $$\begin{array}{rcl}
         E[\underset{j=1}{\overset{m}{\sum}} w_jx_j] &=& \overset{m}{\underset{j=1}{\sum}} w_j P[X_j=1]\\
         &\leq& \overset{m}{\underset{j=1}{\sum}} w_j (c \log \, n)x_j*\\
         &=& c \log \, n \cdot z_{LP}^*\\
         &\leq& OPT
      \end{array}$$
   
      Next we have to proof the more general case.\\

      $A_1, ..., A_n$ disjoined events that form a partition fo the sample space:\\
      $$\begin{array}{rcl}
         E[X] &=& \underset{i}{\overset{n}{\sum}} P(A_i) \cdot E[X \; | \; A_i]\\
         &=& \underset{x}{\sum} x P{X|A} (x)\\
         &=& \frac{P(\{X=x\} \cap A)}{P(A)}
      \end{array}$$

      Let $F$ be events, when the solution is feasale and
      $\overline{F}$ the complement of $F$ in sample space.\\
      And we conclude the probability $P[F] \geq 1 - \frac{1}{n^{c-1}}$
      $$\begin{array}{rcl}
         E[\underset{i=1}{\overset{m}{\sum}} w_jX_j] &=& 
            E[\underset{j=1}{\overset{m}{\sum}} w_jX_j | F]\cdot P[F] + 
            E[\underset{j=1}{\overset{m}{\sum}}w_jX_j | \overline{F}] \cdot P[\overline{F}]\\
      \end{array}$$
      $$\begin{array}{rcl}
            E[\sum | F] &\geq& \frac{1}{P[F]}\left( E[\sum] - E[\sum | \overline{F}] P[\overline{F}]\right)\\
            &\leq & \frac{1}{P[F]} E[\sum w_jx_j]\\
            &\leq & \frac{c\log \, n z_{LP}^*}{1-\frac{1}{n^{c-1}}}\\
            & \leq & 2c (\log \, n) Z_{LP}^* \leq 2c (\log \, n) OPT
      \end{array}$$
      \mbox{}\hfill $\square$
\end{description}

\end{document}
